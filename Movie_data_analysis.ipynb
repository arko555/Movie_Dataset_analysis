{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r'train.csv')\n",
    "test=pd.read_csv(r'test.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After taking an initial glance at the data we can see certain columns are in JSON or DIctionary format so I shall go ahead\n",
    "and take a look at the datatypes that we have for the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train['production_countries'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns were originally in json format but due to the formatting of the csv file were imported as strings into the dataframe, we need to turn the strings back into lists and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the variables which contain the Dictionary format Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_types = ['belongs_to_collection','genres','production_countries','spoken_languages','production_companies','Keywords','cast','crew']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to converts Columns to Dictionary formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(data, cols):\n",
    "    '''\n",
    "    Function to convert string format into dict and list format\n",
    "    Args: data = dataframe\n",
    "          cols = list; header names\n",
    "    Returns: data = dataframe\n",
    "    '''\n",
    "    for col in cols:\n",
    "        data[col] = data[col].apply(lambda x: {} if pd.isna(x) else literal_eval(x))\n",
    "        \n",
    "    return data\n",
    "\n",
    "train = to_dict(train, dict_types)\n",
    "test = to_dict(test, dict_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the Dictionary formatted variables to lists of the value contained in the 'name' key since that is of interest in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dic_to_vals(data, cols):\n",
    "    '''\n",
    "    Function to turn values of dictionary variables into lists of the value of 'name'\n",
    "    Args: dataset = dataframe\n",
    "          headers = list; column headers whose contents need to be transformed\n",
    "    Returns: dataset = dataframe\n",
    "    '''\n",
    "    #Creating temporary columns to store the formatted lists\n",
    "    temp_names = list(map(lambda x: x+'_temp', cols))\n",
    "    for head in temp_names:\n",
    "        data[head] = 0\n",
    "    \n",
    "    #Convert dicts to lists containing only the value in 'name' key\n",
    "    j=0\n",
    "    for org_col in cols:\n",
    "        data[temp_names[j]] = data[org_col].apply(lambda x: ','.join(i['name'] for i in x) if x != {} else '')\n",
    "        j+=1\n",
    "    \n",
    "    return data\n",
    "\n",
    "train = dic_to_vals(train, dict_types)\n",
    "test = dic_to_vals(test, dict_types)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking shape of New Datframes with added columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"budget\", y=\"revenue\", data=train, height=11, ratio=4, color=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Budget and Revenue have somewhat positive correlation however not very strong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"popularity\", y=\"revenue\", data=train, height=11, ratio=4, color=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity quite interestingly also doesn't show a strong correlation with revenue which is quite contradictory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['genres_temp'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the top most popular genres in which movies have been produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "sns.barplot(x='genres_temp', y='revenue', data=train[train['genres_temp'].isin(['Drama','Comedy','Drama,Romance','Comedy,Romance','Comedy,Drama'])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The barplot above depicts the revenue generated by the most popular Genres and Comedy and Romance seem to dominate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"runtime\", y=\"revenue\", data=train, height=11, ratio=4, color=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A jointplot of Runtime and Rrevenue shows not positive correlation and also shows that most movies have a mean runtime of about 100 to 150 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "sns.distplot(train.revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the revenue column seems to be quite right skewed to we shall use a Log-Transformation to make it resemble a normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['log_revenue']=np.log(train['revenue'])\n",
    "sns.kdeplot(train.log_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['release_month','release_date','release_year']]=train['release_date'].str.split('/', expand=True).replace(np.nan, -1).astype('int')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Release Data column such that Date, Month and Year and store them in seperate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['release_year'] = train['release_year'].apply(lambda x: x+1900 if x>19 else x+2000).astype(int)\n",
    "\n",
    "train['release_year'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Release Year column is a little ambiguous since we dont know if its for 20th Century or 21st Century I have converted the column to show full year instead of last 2 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(train['release_year'])\n",
    "plt.title(\"Movie Release count by Year\",fontsize=20)\n",
    "#loc, labels = plt.xticks()\n",
    "plt.xticks(fontsize=12,rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the frequency of movies produced every year and 2013 seems to have the highest count. Its also interesting to note that there is strong upward curve of movie productions since 1976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(train['release_month'])\n",
    "plt.title(\"Movie Release count by Month\",fontsize=20)\n",
    "#loc, labels = plt.xticks()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(train['release_date'])\n",
    "plt.title(\"Movie Release count by Day\",fontsize=20)\n",
    "#loc, labels = plt.xticks()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['release_fulldate'] = train[['release_date','release_month','release_year']].apply(lambda x: '/'.join(x.values.astype(str)), axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating the release full-date column which I had replaced earlier to do certain time based analysis down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['release_fulldate'] = pd.to_datetime(train['release_fulldate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day_of_week'] = train['release_fulldate'].dt.dayofweek\n",
    "train['release_quarter'] = train['release_fulldate'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Day of week and Quarter of year to further analyse and gain insight about how movies ae released and what time is optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(train['day_of_week'])\n",
    "plt.title(\"Movie Release count by DayOFWeek\",fontsize=20)\n",
    "#loc, labels = plt.xticks()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.countplot(train['release_quarter'])\n",
    "plt.title(\"Movie Release count by Quarter\",fontsize=20)\n",
    "#loc, labels = plt.xticks()\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = train.groupby('release_year')['revenue'].agg('mean').reset_index()\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.lineplot(x='release_year', y='revenue', data=d1)\n",
    "plt.title(\"Avg Revenue by Year\",fontsize=20)\n",
    "labels = np.arange(1920,2019,4)\n",
    "plt.xticks(labels,fontsize=12,rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = train.groupby('day_of_week')['revenue'].agg('mean').reset_index()\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='day_of_week', y='revenue', data=d1)\n",
    "plt.title(\"Avg Revenue by Day of Week\",fontsize=20)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = train.groupby('release_quarter')['revenue'].agg('mean').reset_index()\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='release_quarter', y='revenue', data=d1)\n",
    "plt.title(\"Avg Revenue by Day of Quarter\",fontsize=20)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = train.groupby('release_year')['runtime'].agg('mean').reset_index()\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='release_year', y='runtime', data=d1)\n",
    "plt.title(\"Avg runtime by Year\",fontsize=20)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = train.groupby('release_year')['popularity'].agg('mean').reset_index()\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.lineplot(x='release_year', y='popularity', data=d1)\n",
    "plt.title(\"Avg poularity by Year\",fontsize=20)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = train.groupby('release_year')['budget','revenue'].agg('mean').reset_index()\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(d1['release_year'], d1[['budget','revenue']], color=\"g\")\n",
    "plt.xticks(np.arange(1920,2018,4), rotation=90)\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"revenue & budget\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = train.genres_temp.str.get_dummies(sep=',')\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, genres], axis=1, sort=False)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=['Action', 'Adventure', 'Animation',\n",
    "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
    "       'Foreign', 'History', 'Horror', 'Music', 'Mystery', 'Romance',\n",
    "       'Science Fiction', 'TV Movie', 'Thriller', 'War', 'Western']\n",
    "\n",
    "counter=0\n",
    "\n",
    "fig, ax= plt.subplots(7, 3, figsize=[20,15])\n",
    "\n",
    "for j in range(len(ax)):\n",
    "    for i in range(3):\n",
    "        if j==6 & i==2:\n",
    "            break\n",
    "        else:\n",
    "            ax[j][i] = sns.violinplot(x=genres[counter], y='revenue', data=train, ax=ax[j][i])\n",
    "            ax[j][i].set_xlabel(genres[counter])\n",
    "            ax[j][i].set_ylabel('Revenue')\n",
    "            counter+=1\n",
    "            \n",
    "fig.delaxes(ax=ax[2,2])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['belongs'] = train['belongs_to_collection'].apply(lambda x: 1 if x != {} else 0)\n",
    "\n",
    "sns.boxplot(x = 'belongs', y='revenue', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_comp = train.production_companies_temp.str.get_dummies(sep=',')\n",
    "prod_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_comp = train.cast_temp.str.get_dummies(sep=',')\n",
    "cast_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = prod_comp.sum(axis=0).sort_values(ascending=False).head(15).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cast_comp.sum(axis=0).sort_values(ascending=False).head(30).reset_index()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(x.loc[:,'index'])\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = list(y.loc[:,'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_comp = prod_comp.drop(prod_comp.columns.difference(l1), axis=1)\n",
    "prod_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_comp = cast_comp.drop(cast_comp.columns.difference(l2), axis=1)\n",
    "cast_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, cast_comp], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, prod_comp], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_house=['Canal+', 'Columbia Pictures', 'Columbia Pictures Corporation',\n",
    "       'Metro-Goldwyn-Mayer (MGM)', 'Miramax Films', 'New Line Cinema',\n",
    "       'Paramount Pictures', 'Relativity Media', 'Touchstone Pictures',\n",
    "       'TriStar Pictures', 'Twentieth Century Fox Film Corporation',\n",
    "       'United Artists', 'Universal Pictures', 'Walt Disney Pictures',\n",
    "       'Warner Bros.']\n",
    "\n",
    "counter=0\n",
    "\n",
    "fig, ax= plt.subplots(5, 3, figsize=[15,29])\n",
    "\n",
    "for j in range(len(ax)):\n",
    "    for i in range(3):\n",
    "        if j==4 & i==2:\n",
    "            break\n",
    "        else:\n",
    "            ax[j][i] = sns.boxplot(x=prod_house[counter], y='revenue', data=train, ax=ax[j][i])\n",
    "            ax[j][i].set_xlabel(prod_house[counter])\n",
    "            ax[j][i].set_ylabel('Revenue')\n",
    "            counter+=1\n",
    "            \n",
    "#fig.delaxes(ax=ax[2,2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['log_revenue','belongs_to_collection','Keywords','cast','crew','release_month','day_of_week','release_quarter','production_companies_temp','genres_temp','poster_path','homepage'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['original_language'] = train['original_language'].apply(lambda x: 1 if x=='en' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['production_countries_temp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBC\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgm=XGBRegressor()\n",
    "GBM=GBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.iloc[:, 46:61], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm = GridSearchCV(GBM, param_grid = {'learning_rate':[0.01,0.05,0.1], 'max_depth':[1,2,3], 'n_estimators':[100,200,500]}, cv=5, n_jobs=-1)\n",
    "best_xgm = GridSearchCV(xgm, param_grid = {'learning_rate':[0.01,0.05,0.1], 'max_depth':[1,2,3], 'n_estimators':[100,200,500]}, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop(['revenue','id','genres','imdb_id','overview','production_companies','production_countries','release_date','spoken_languages','status','tagline','title','belongs_to_collection_temp','spoken_languages_temp','Keywords_temp','crew_temp','original_title','release_fulldate','production_countries_temp','cast_temp'], axis=1)\n",
    "Y=train['revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['runtime'] = X['runtime'].fillna((X['runtime'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm.fit(X, Y)\n",
    "best_xgm.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(best_gbm.best_estimator_, X=X, y=Y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(best_xgm.best_estimator_, X=X, y=Y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
